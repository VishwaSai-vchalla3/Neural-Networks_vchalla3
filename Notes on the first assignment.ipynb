{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c30d3a",
   "metadata": {},
   "source": [
    "# The Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aad8440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the numpy and the matplotlib libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb6a458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1 ...       1       1       2]\n",
      " [1002945       5       4 ...       2       1       2]\n",
      " [1015425       3       1 ...       1       1       2]\n",
      " ...\n",
      " [ 888820       5      10 ...      10       2       4]\n",
      " [ 897471       4       8 ...       6       1       4]\n",
      " [ 897471       4       8 ...       4       1       4]]\n"
     ]
    }
   ],
   "source": [
    "# read the CSV file into the two-dimensional array \"data\"\n",
    "# using numpy's function genfromtxt\n",
    "\n",
    "data = np.genfromtxt('breast-cancer-wisconsin.data.csv',delimiter=',').astype(int)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd1f0ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 11)\n"
     ]
    }
   ],
   "source": [
    "# print the shape of the array \"data\"\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4a3dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000025       5       1       1       1       2       1       3       1\n",
      "        1       2]\n",
      " [1002945       5       4       4       5       7      10       3       2\n",
      "        1       2]\n",
      " [1015425       3       1       1       1       2       2       3       1\n",
      "        1       2]\n",
      " [1016277       6       8       8       1       3       4       3       7\n",
      "        1       2]\n",
      " [1017023       4       1       1       3       2       1       3       1\n",
      "        1       2]]\n"
     ]
    }
   ],
   "source": [
    "# print the first 5 rows of the array \"data\"\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421960d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  1  1 ...  3  1  1]\n",
      " [ 5  4  4 ...  3  2  1]\n",
      " [ 3  1  1 ...  3  1  1]\n",
      " ...\n",
      " [ 5 10 10 ...  8 10  2]\n",
      " [ 4  8  6 ... 10  6  1]\n",
      " [ 4  8  8 ... 10  4  1]]\n"
     ]
    }
   ],
   "source": [
    "# Assign to the array \"X\" the features from the array \"data\"\n",
    "# do we need to ignore any feature (column)?\n",
    "X=data[:,1:10]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc6d5a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1.\n",
      " 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Assign to the array \"y\" the labels from the array \"data\"\n",
    "# Do we need to adjust the values in \"y\"?\n",
    "y=data[:,10]/2-1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba9cd8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train is: [[5 2 2 ... 2 2 1]\n",
      " [4 1 1 ... 3 1 1]\n",
      " [1 1 1 ... 2 1 1]\n",
      " ...\n",
      " [7 9 4 ... 5 3 3]\n",
      " [1 1 1 ... 2 1 1]\n",
      " [5 1 1 ... 3 3 1]]\n",
      "X_train shape is: (559, 9)\n",
      "y_train is: [0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1.\n",
      " 1. 1. 1. 0. 1. 0. 0.]\n",
      "y_train shape is: (559,)\n",
      "X_test is: [[7 1 2 ... 2 1 1]\n",
      " [3 1 1 ... 1 1 1]\n",
      " [8 6 5 ... 6 1 1]\n",
      " ...\n",
      " [4 1 1 ... 2 1 1]\n",
      " [1 6 8 ... 5 7 1]\n",
      " [3 1 1 ... 3 2 1]]\n",
      "X_test shape is: (140, 9)\n",
      "y_test is: [0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "y_test shape is: (140,)\n"
     ]
    }
   ],
   "source": [
    "# Split X (the features) and y (the labels) into traing and testing sets:\n",
    "# X_train, y_train, X_test, y_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=47)\n",
    "#test sizes to be tested are 0.1(90% 10%) 0.2(80% 20%) 0.4(60% 40%)(train test) data's..\n",
    "print(\"X_train is:\",X_train)\n",
    "print(\"X_train shape is:\",X_train.shape)\n",
    "print(\"y_train is:\",y_train)\n",
    "print(\"y_train shape is:\",y_train.shape)\n",
    "print(\"X_test is:\",X_test)\n",
    "print(\"X_test shape is:\",X_test.shape)\n",
    "print(\"y_test is:\",y_test)\n",
    "print(\"y_test shape is:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d08dc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 4 1 ... 7 1 5]\n",
      " [2 1 1 ... 9 1 1]\n",
      " [2 1 1 ... 4 1 1]\n",
      " ...\n",
      " [2 3 2 ... 5 2 3]\n",
      " [2 1 1 ... 3 1 3]\n",
      " [1 1 1 ... 3 1 1]]\n",
      "(9, 559)\n"
     ]
    }
   ],
   "source": [
    "# The algorithm we discussed in class assumes that the features array to have the dimensions n rows by m columns\n",
    "# where n is the number of features and m is the size of the data\n",
    "# Make sure that X_train and X_test have the correct dimensions\n",
    "\n",
    "x = X_train.T  #Transposing the training data to make the dimensions adjustment..\n",
    "print(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2c09f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 3 8 ... 4 1 3]\n",
      " [1 1 6 ... 1 6 1]\n",
      " [2 1 5 ... 1 8 1]\n",
      " ...\n",
      " [2 1 6 ... 2 5 3]\n",
      " [1 1 1 ... 1 7 2]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "(9, 140)\n"
     ]
    }
   ],
   "source": [
    "#Adjusting the dimensions..\n",
    "x1 = X_test.T\n",
    "print(x1)\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4506ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sigmoid function and the derivative of the sigmoid function\n",
    "\n",
    "def g(z):\n",
    "    return 1./(1+np.exp(-z))\n",
    "\n",
    "def g1_prime(z):\n",
    "    return g(z)*(1-g(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ed28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to initialize the weight and bias matrices\n",
    "\n",
    "#weight and bias matrices to be intialized.\n",
    "def initializeWb(x, y, n_h, n_y):\n",
    "    n_x= x.shape[0]#features of the data\n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.1\n",
    "    b1 = np.random.randn(n_h,1)\n",
    "    W2 = np.random.randn(n_y,n_h)\n",
    "    b2 = np.random.randn(n_y,1)\n",
    "    \n",
    "    return W1,b1,W2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65c920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the function \"nn\" that does the training of a model\n",
    "\n",
    "def nn(x, y, n_h, n_y, alpha, iterations):\n",
    "    \n",
    "    stage_1 = iterations//2; alpha2 = alpha/2.\n",
    "    stage_2 = iterations//1.75; alpha3 = alpha/4.\n",
    "    stage_3 = iterations//1.5; alpha4 = alpha/8.\n",
    "    \n",
    "    cost_list = [[],[]]\n",
    "    m=x.shape[1]     #size of the data..\n",
    "    W1,b1,W2,b2 = initializeWb(x, y, n_h, n_y)\n",
    "    for i in range(iterations):\n",
    "        #Forward propagation..(This will produce the outputs as the inputs are passed..)\n",
    "        Z1 = np.dot(W1,x) + b1\n",
    "        A1 = g(Z1)\n",
    "        \n",
    "        Z2 = np.dot(W2,A1) + b2\n",
    "        A2 = g(Z2)\n",
    "        \n",
    "        #loss function..(the diff between the o/p obtained and o/p expected.)\n",
    "        if iterations%100==0:\n",
    "            #cost = -np.sum(y*np.log(A2)+(1-y)*np.log(1-A2))\n",
    "            cost = np.sum(np.sqrt(((y-A2)**2).mean()))\n",
    "            cost_list[0].append(i)\n",
    "            cost_list[1].append(cost)\n",
    "        \n",
    "        #Backward propagation..(Weights are adjusted using the gradient mode..)\n",
    "        dZ2 = A2-y\n",
    "        dW2 = (1/m)*np.dot(dZ2,A1.T)\n",
    "        db2 = (1/m)*np.sum(dZ2)\n",
    "        \n",
    "        dZ1 = np.dot(W2.T,dZ2)*g1_prime(Z1)\n",
    "        dW1 = (1/m)*np.dot(dZ1,x.T)\n",
    "        db1 = (1/m)*np.sum(dZ1)\n",
    "        \n",
    "        W2 = W2-alpha*dW2\n",
    "        b2 = b2-alpha*db2\n",
    "        W1 = W1-alpha*dW1\n",
    "        b1 = b1-alpha*db1\n",
    "        \n",
    "        if i>stage_1:     #(Based on the number of iterations the stepsize is adjusted to obtain the accurate values.)\n",
    "            alpha = alpha2\n",
    "        elif i>stage_2:\n",
    "            alpha = alpha3\n",
    "        elif i>stage_3:\n",
    "            alpha = alpha4\n",
    "\n",
    "        \n",
    "    return W1,b1,W2,b2,cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd04c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the function \"nn\" that does the training of a model\n",
    "\n",
    "def nn(x, y, n_h, n_y, alpha, iterations, batch_size):\n",
    "    \n",
    "    stage_1 = iterations//2; alpha2 = alpha/2.\n",
    "    stage_2 = iterations//1.75; alpha3 = alpha/4.\n",
    "    stage_3 = iterations//1.5; alpha4 = alpha/8.\n",
    "    \n",
    "    cost_list = [[],[]]\n",
    "    m=x.shape[1]     #size of the data..\n",
    "    W1,b1,W2,b2 = initializeWb(x, y, n_h, n_y)\n",
    "    for i in range(iterations):\n",
    "        for j in range(0, m, batch_size):   #Performing this for 80% of the data..\n",
    "            X_batch = x[:, j:j+batch_size]\n",
    "            y_batch = y[j:j+batch_size]\n",
    "            Z1 = np.dot(W1, X_batch) + b1\n",
    "            A1 = g(Z1)\n",
    "            Z2 = np.dot(W2, A1) + b2\n",
    "            A2 = g(Z2)\n",
    "            dZ2 = A2 - y_batch\n",
    "            dW2 = (1/m) * np.dot(dZ2, A1.T)\n",
    "            db2 = (1/m) * np.sum(dZ2)\n",
    "            dZ1 = np.dot(W2.T, dZ2) * g1_prime(Z1)\n",
    "            dW1 = (1/m) * np.dot(dZ1, X_batch.T)\n",
    "            db1 = (1/m) * np.sum(dZ1)\n",
    "            W2 = W2 - alpha * dW2\n",
    "            b2 = b2 - alpha * db2\n",
    "            W1 = W1 - alpha * dW1\n",
    "            b1 = b1 - alpha * db1\n",
    "            if i>stage_3:\n",
    "                alpha = alpha4\n",
    "            elif i>stage_2:\n",
    "                alpha = alpha3\n",
    "            elif i>stage_1:\n",
    "                alpha = alpha2\n",
    "                \n",
    "        if iterations%100==0:\n",
    "            Z1 = np.dot(W1, X_batch) + b1\n",
    "            A1 = g(Z1)\n",
    "            Z2 = np.dot(W2, A1) + b2\n",
    "            A2 = g(Z2)\n",
    "            cost = -np.sum(y_batch*np.log(A2)+(1-y_batch)*np.log(1-A2))\n",
    "            cost_list[0].append(i)\n",
    "            cost_list[1].append(cost)\n",
    "\n",
    "    return W1, b1, W2, b2, cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4928170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters needed for traing the model\n",
    "# Initialize your weight matrices\n",
    "# call the the \"nn\" function to train the model on the testing data\n",
    "# Testing the batch_size code\n",
    "n_h = 8;n_y = 1\n",
    "alpha = 0.05\n",
    "iterations = 1000\n",
    "batch_size = 32\n",
    "W1,b1,W2,b2,cost_list = nn(x, y_train, n_h, n_y, alpha, iterations, batch_size)\n",
    "print('W1=',W1, '\\n', 'b1=',b1, '\\n', 'W2=',W2, '\\n', 'b2=',b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7572733a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1= [[ 5.37377287e-01  1.17587300e-01  2.26798914e-01  2.63528608e-01\n",
      "   2.65899728e-01  4.28000739e-01  1.26416954e-01  2.59357395e-01\n",
      "  -8.38592242e-02]\n",
      " [ 3.38227095e-01  3.02398495e-01  3.34973852e-01  2.21518727e-01\n",
      "   4.69265925e-01  2.05386924e-01  5.02471036e-01  3.44274121e-01\n",
      "   3.43180352e-01]\n",
      " [-6.70018799e-01  9.81711463e-01  1.20680608e-01 -7.15192213e-01\n",
      "  -3.32478024e-01 -6.09905970e-01 -4.17096125e-02 -6.36644225e-01\n",
      "  -5.67265264e-01]\n",
      " [ 4.75404607e-02 -5.05267453e-02  1.14310918e-01  6.59940106e-04\n",
      "   4.63256895e-02  1.05588918e-01  6.67069629e-02  1.69684438e-01\n",
      "  -8.40986778e-02]\n",
      " [-3.37581907e-01  2.58477656e-01  3.01156915e-01 -1.47190625e-01\n",
      "  -8.01699713e-03  3.14191749e-01  5.11953063e-02  6.66984153e-02\n",
      "   1.97191554e-02]\n",
      " [ 1.04462431e-01 -1.86378067e+00 -2.03759207e-01  7.21542602e-01\n",
      "   1.75328479e+00 -2.08789559e+00  2.71020157e-01 -3.71337934e-01\n",
      "  -1.06199251e+00]\n",
      " [-2.41787713e-01  5.64231124e-01 -4.85543477e-01 -1.99670961e-01\n",
      "  -3.56814215e-01  4.28136984e-01 -1.59129706e+00 -2.46993117e-01\n",
      "  -2.63105458e-01]\n",
      " [ 1.19715676e+00  1.67067851e+00  1.55842608e+00 -5.60874165e-01\n",
      "  -1.31202188e+00 -6.59525757e-01 -1.19629157e+00 -1.11384845e+00\n",
      "  -5.43167047e-01]] \n",
      " b1= [[5.48940059]\n",
      " [6.00166481]\n",
      " [7.23767675]\n",
      " [7.29162097]\n",
      " [6.46216086]\n",
      " [6.58615863]\n",
      " [7.15673186]\n",
      " [5.26399408]] \n",
      " W2= [[ 0.44050667 -0.66896753 -6.10698075  1.1508182   2.24517121 -6.58718542\n",
      "  -6.1632852   4.94631386]] \n",
      " b2= [[0.81429484]]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters needed for traing the model\n",
    "# Initialize your weight matrices\n",
    "# call the the \"nn\" function to train the model on the testing data\n",
    "#5,8,10\n",
    "n_h = 8;n_y = 1\n",
    "alpha = 0.05\n",
    "iterations = 50000\n",
    "W1,b1,W2,b2,cost_list = nn(x, y_train, n_h, n_y, alpha, iterations)\n",
    "print('W1=',W1, '\\n', 'b1=',b1, '\\n', 'W2=',W2, '\\n', 'b2=',b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d889248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e00f9fb050>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a plot of the loss as a function of the number of iterations\n",
    "plt.plot(cost_list[0][1:], cost_list[1][1:], 'go')\n",
    "\n",
    "#Plotted the relationship between the number of iterations and the diff between the o/p obtained and o/p expected.\n",
    "#As the number of iterations increases the weights are adjusted such that diff between the o/p obtained and o/p expected is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269b1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.92257137e-02 9.12955957e-05 9.99443204e-01 9.99675817e-01\n",
      "  9.26025302e-01 7.27160256e-03 9.59990912e-01 3.74417440e-05\n",
      "  2.53677817e-04 9.35874213e-05 1.46025095e-04 9.35874213e-05\n",
      "  9.99549855e-01 1.43319307e-04 3.77449086e-04 9.90596469e-01\n",
      "  4.54788024e-05 2.07845411e-04 9.35874213e-05 3.77449086e-04\n",
      "  7.96901919e-04 4.54788024e-05 9.99489875e-01 3.36352772e-04\n",
      "  7.27850390e-02 9.99853355e-01 1.58444230e-04 4.57636634e-05\n",
      "  1.03941227e-04 3.59696295e-03 9.99856193e-01 4.90521380e-05\n",
      "  1.58444230e-04 9.84904361e-01 8.83160610e-01 7.10124709e-05\n",
      "  9.81658741e-01 9.75293453e-01 9.81642188e-01 9.99866800e-01\n",
      "  1.03941227e-04 1.56314813e-03 5.01014469e-05 9.99245546e-01\n",
      "  4.91069110e-04 4.94304124e-03 6.08014798e-03 1.00149228e-01\n",
      "  9.99663679e-01 2.85700185e-04 9.36616559e-05 9.90354573e-01\n",
      "  3.73697491e-05 9.99230632e-01 6.39774705e-05 3.74417440e-05\n",
      "  9.82652408e-01 9.91394636e-01 1.51557408e-04 9.99789370e-01\n",
      "  1.03941227e-04 5.11372492e-05 3.74417440e-05 9.52386902e-01\n",
      "  1.46025095e-04 2.04311800e-04 9.13793657e-02 3.40731796e-02\n",
      "  5.81645407e-05 3.74417440e-05 6.47561521e-03 9.42904202e-04\n",
      "  4.25990424e-04 9.99802963e-01 2.37318508e-04 6.39774705e-05\n",
      "  9.95470792e-01 9.99860654e-01 1.51557408e-04 1.03941227e-04\n",
      "  1.46025095e-04 3.73697491e-05 1.36250190e-01 9.99789047e-01\n",
      "  9.99795237e-01 4.54788024e-05 1.51557408e-04 9.99863918e-01\n",
      "  9.99851874e-01 2.37173975e-04 1.18659872e-04 3.73697491e-05\n",
      "  1.06999276e-04 9.99831757e-01 9.70268952e-01 3.70884166e-04\n",
      "  9.42904202e-04 9.99826092e-01 1.30007301e-04 1.85485674e-04\n",
      "  3.74417440e-05 9.88588764e-01 5.27632156e-03 8.70831954e-01\n",
      "  9.99866074e-01 9.84519857e-01 1.66568485e-03 9.99856523e-01\n",
      "  7.96901919e-04 9.80683579e-01 4.54788024e-05 9.81665341e-01\n",
      "  9.81785726e-01 6.43640050e-04 9.99866039e-01 5.66282290e-06\n",
      "  2.57900976e-05 3.74417440e-05 8.44027118e-01 9.81684214e-01\n",
      "  2.85700185e-04 9.50993503e-01 1.14754381e-04 6.96933925e-05\n",
      "  3.73697491e-05 9.82356757e-01 9.81053256e-01 1.96276476e-03\n",
      "  1.49568712e-04 9.88593731e-01 9.83826350e-05 8.43464254e-05\n",
      "  9.96362039e-01 3.99739076e-04 9.85636102e-01 9.11141821e-04\n",
      "  9.99831851e-01 1.58444230e-04 9.79733711e-01 4.45704147e-04]]\n"
     ]
    }
   ],
   "source": [
    "# Using the trained model, predict the labels for the testing data\n",
    "\n",
    "Z1 = np.dot(W1, x1) + b1\n",
    "A1 = g(Z1)\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = g(Z2)\n",
    "print(A2)\n",
    "\n",
    "#Block of code which will pass the test data to check whether the model trained is properly or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138159cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "(140,)\n",
      "[0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1.\n",
      " 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0.]\n",
      "(140,)\n"
     ]
    }
   ],
   "source": [
    "# make sure that the array of the predicted labels has the same dimension as the testing data\n",
    "predictions = np.ravel(np.rint(A2.copy()))\n",
    "print(predictions)\n",
    "print(predictions.shape)\n",
    "print(y_test)\n",
    "print(y_test.shape)\n",
    "\n",
    "#rint function will round of the values to the nearest integer.\n",
    "#ravel function will flatten the multi dimension array to the flat array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dd0a3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  1]\n",
      " [ 4 51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97        85\n",
      "         1.0       0.98      0.93      0.95        55\n",
      "\n",
      "    accuracy                           0.96       140\n",
      "   macro avg       0.97      0.96      0.96       140\n",
      "weighted avg       0.96      0.96      0.96       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the confusion matrix for the testing data\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "#confusion matrix(Gives the relationship between the output predicted and output obtained based on the passed input.)\n",
    "#classification report(Gives the detailed report for the output matrix.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5eb9b19",
   "metadata": {},
   "source": [
    "# Number of Neurons in the Hidden Layer = 8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34fce58b",
   "metadata": {},
   "source": [
    "[[84  1]\n",
    " [ 6 49]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.93      0.99      0.96        85\n",
    "         1.0       0.98      0.89      0.93        55\n",
    "\n",
    "    accuracy                           0.95       140\n",
    "   macro avg       0.96      0.94      0.95       140\n",
    "weighted avg       0.95      0.95      0.95       140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175d3753",
   "metadata": {},
   "source": [
    "# Number of Neurons in the Hidden Layer = 5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ff720cf",
   "metadata": {},
   "source": [
    "[[84  1]\n",
    " [ 3 52]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.99      0.98        85\n",
    "         1.0       0.98      0.95      0.96        55\n",
    "\n",
    "    accuracy                           0.97       140\n",
    "   macro avg       0.97      0.97      0.97       140\n",
    "weighted avg       0.97      0.97      0.97       140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246778b4",
   "metadata": {},
   "source": [
    "# Number of Neurons in the Hidden Layer = 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8aa542a",
   "metadata": {},
   "source": [
    "[[84  1]\n",
    " [ 5 50]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.94      0.99      0.97        85\n",
    "         1.0       0.98      0.91      0.94        55\n",
    "\n",
    "    accuracy                           0.96       140\n",
    "   macro avg       0.96      0.95      0.95       140\n",
    "weighted avg       0.96      0.96      0.96       140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d92e0d7",
   "metadata": {},
   "source": [
    "# Train data=60% and Test data=40% and N.O neurons=8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0ef7cb0",
   "metadata": {},
   "source": [
    "[[172   9]\n",
    " [  6  93]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.95      0.96       181\n",
    "         1.0       0.91      0.94      0.93        99\n",
    "\n",
    "    accuracy                           0.95       280\n",
    "   macro avg       0.94      0.94      0.94       280\n",
    "weighted avg       0.95      0.95      0.95       280"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a78ac8",
   "metadata": {},
   "source": [
    "# Train data=90% and Test data=10% and N.O neurons=8"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78fea7c5",
   "metadata": {},
   "source": [
    "[[44  1]\n",
    " [ 3 22]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.94      0.98      0.96        45\n",
    "         1.0       0.96      0.88      0.92        25\n",
    "\n",
    "    accuracy                           0.94        70\n",
    "   macro avg       0.95      0.93      0.94        70\n",
    "weighted avg       0.94      0.94      0.94        70"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643311d",
   "metadata": {},
   "source": [
    "# Test with cost function as root mean square error"
   ]
  },
  {
   "cell_type": "raw",
   "id": "957a50a3",
   "metadata": {},
   "source": [
    "[[84  1]\n",
    " [ 4 51]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.95      0.99      0.97        85\n",
    "         1.0       0.98      0.93      0.95        55\n",
    "\n",
    "    accuracy                           0.96       140\n",
    "   macro avg       0.97      0.96      0.96       140\n",
    "weighted avg       0.96      0.96      0.96       140"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedbf0ee",
   "metadata": {},
   "source": [
    "# Test when batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "raw",
   "id": "d99e2772",
   "metadata": {},
   "source": [
    "[[84  1]\n",
    " [ 2 53]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.98      0.99      0.98        85\n",
    "         1.0       0.98      0.96      0.97        55\n",
    "\n",
    "    accuracy                           0.98       140\n",
    "   macro avg       0.98      0.98      0.98       140\n",
    "weighted avg       0.98      0.98      0.98       140\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19feed15",
   "metadata": {},
   "source": [
    "# Test when batch_size = 64"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d52352d3",
   "metadata": {},
   "source": [
    "[[84  1]\n",
    " [ 3 52]]\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.97      0.99      0.98        85\n",
    "         1.0       0.98      0.95      0.96        55\n",
    "\n",
    "    accuracy                           0.97       140\n",
    "   macro avg       0.97      0.97      0.97       140\n",
    "weighted avg       0.97      0.97      0.97       140\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
